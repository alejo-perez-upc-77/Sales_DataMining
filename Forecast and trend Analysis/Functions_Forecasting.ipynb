{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import *\n",
    "import math\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from sklearn import linear_model as lm  # Used for solving linear regression problems\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import cmath\n",
    "import math\n",
    "import datetime as dt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc69ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_purchases(df_agg_hours,timestamp_agg_hours, ItemID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a dataframe with the chosen ItemID and its purchases every hour \n",
    "    Arguments:\n",
    "        :df_agg_hours: df with the aggregated purchases by timestamp (day+hour) and ItemID\n",
    "        :ItemID: Size of the plot, tuple\n",
    "        :timestamp_agg_hours: Support dictionary that has all the hours during the month to be filled\n",
    "        Returns:\n",
    "        Hourly Purchases of ItemID == ID in a DataFrame.\n",
    "    \"\"\"\n",
    "    # add 0 sales hours for product\n",
    "    support = dict(zip(timestamp_agg_hours,[0]*len(timestamp_agg_hours)))\n",
    "    filler = df_agg_hours[df_agg_hours['ItemID']==ItemID]\n",
    "    \n",
    "    \n",
    "    for i in range(len(filler)):\n",
    "        support[filler.iloc[i,0]] = filler.iloc[i,-1]\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(support.items(), columns=['timestamp', 'quantity']).set_index('timestamp')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_purchases(df_agg_days, timestamp_agg_days, ItemID):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates a dataframe with the chosen ItemID and its purchases every hour \n",
    "    Arguments:\n",
    "        :df_agg_days: df with the aggregated purchases by day and ItemID\n",
    "        :ItemID: Size of the plot, tuple\n",
    "        Returns:\n",
    "        Daily Purchases of ItemID == ID in a DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # add 0 sales days for product\n",
    "\n",
    "    support = dict(zip(timestamp_agg_days,[0]*len(timestamp_agg_days)))\n",
    "    filler = df_agg_days[df_agg_days['ItemID']==ItemID]\n",
    "    \n",
    "    for i in range(len(filler)):\n",
    "        support[filler.iloc[i,0]] = filler.iloc[i,-1]\n",
    "\n",
    "    df = pd.DataFrame(support.items(), columns=['DayDate', 'quantity']).set_index('DayDate')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trend_item(name_product, series, daily, size=(20, 8), interval = 10):\n",
    "    \"\"\"\n",
    "    Plots the trend of an item groupped in the span of days of hours.\n",
    "    Arguments:\n",
    "        :name_product: NameID to be shown in title\n",
    "        :series: DF with 2 columns: one has to be date times (%Y-%m-%d or %Y-%m-%d %H) and the other the \n",
    "            actual frequency counting of that product\n",
    "        :size: Size of the plot, tuple\n",
    "        :daily: boolean, True if the aggregation is daily based, False if hourly\n",
    "        Returns:\n",
    "        Plot of this Series\n",
    "    \"\"\"\n",
    "    # Define plot space\n",
    "    \n",
    "    # define if hourly\n",
    "    time_span = \"Daily\" if daily else \"Hourly\"\n",
    "\n",
    "    plt.figure(figsize=size)    \n",
    "    plt.title(time_span + \" purchase trend of item = \" + name_product, size=20)    \n",
    "    plt.plot(series, label='sales', color=\"blue\")   \n",
    "    \n",
    "    # Tick Freq\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=interval))\n",
    "\n",
    "\n",
    "    plt.xlabel(\"Time (\" + time_span + \")\", size=20)\n",
    "    plt.ylabel(\"Units Sales\", size=20)\n",
    "\n",
    "    \n",
    "    plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 90-degrees\n",
    "\n",
    "    plt.grid(True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedafdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_1step(y_pred, y_true, name_item, train_size, daily=1, size=(25,8), interval = 2):\n",
    "     \n",
    "    \"\"\"\n",
    "    Plots predictions of the forecasting model and the background truth of the corresponding timestamps\n",
    "    Arguments:\n",
    "        :y_pred: Series of the predictions and Time Stamps as index\n",
    "        :y_true: Series of the True and Time Stamps as index. dimensions must much y_pred\n",
    "        :name_item: String, name of the product for the title \n",
    "        :train_size: To plot vertical line in the burn-in period. Actually pass train-p because in the predictions \n",
    "        :there is a burn-in period used to learn the model params\n",
    "        :daily: boolean, True if the aggregation is daily based, False if hourly (just title purposes)\n",
    "        :size: Size of the plot, tuple\n",
    "        Returns:\n",
    "        Plot of this Series\n",
    "    \"\"\"\n",
    "        \n",
    "    # define if hourly\n",
    "    time_span = \"Daily\" if daily else \"Hourly\"\n",
    "    \n",
    "    plt.title(\"1-step-ahead prediction for product = \" + name_item, size=20)    \n",
    "    plt.plot(y_pred, label='Sales Predicted', color=\"blue\")   \n",
    "    plt.plot(y_true, label='True Sales', color=\"brown\")   \n",
    "    \n",
    "    # Tick Freq\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=interval))\n",
    "    plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 90-degrees\n",
    "\n",
    "    plt.xlabel(\"Time (\" + time_span + \")\", size=20)\n",
    "    plt.ylabel(\"Units Sales\", size=20)\n",
    "\n",
    "    # Burn-in vert line\n",
    "    plt.axvline(x = train_size, color = 'red', linestyle= '--', label = 'burn-in period')\n",
    "\n",
    "    \n",
    "    plt.grid(True)\n",
    "\n",
    "    \n",
    "    plt.legend(fontsize='xx-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ar_1step(theta, y_target):\n",
    "    \"\"\"Predicts the value y_t for t = p+1, ..., n, for an AR(p) model, based on the data in y_target using\n",
    "    one-step-ahead prediction.\n",
    "\n",
    "    :param theta: array (p,), AR coefficients, theta=(a1,a2,...,ap).\n",
    "    :param y_target: array (n,), the data points used to compute the predictions.\n",
    "    :return y_pred: array (n-p,), the one-step predictions (\\hat y_{p+1}, ...., \\hat y_n) \n",
    "    \"\"\"\n",
    "\n",
    "    n = len(y_target)\n",
    "    p = theta.shape[1]\n",
    "    \n",
    "    # Number of steps in prediction\n",
    "    m = n-p\n",
    "    y_pred = np.zeros(m+1)\n",
    "    \n",
    "    # Go predict\n",
    "    for i in range(m):\n",
    "        y_pred[i] =  (np.flip(y_target[i:i+p]) * theta).sum()\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ar(y, p):\n",
    "    \"\"\"Fits an AR(p) model. The loss function is the sum of squared errors from t=p+1 to t=n.\n",
    "\n",
    "    :param y: array (n,), training data points\n",
    "    :param p: int, AR model order\n",
    "    :return theta: array (p,), learnt AR coefficients\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of training data points\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    # Construct the regression matrix\n",
    "    Phi = np.zeros((n-p, p))\n",
    "    for j in range(p):\n",
    "        Phi[:,j] = y[(p-(j+1)): (n-(j+1)), 0] \n",
    "    \n",
    "    # Drop the first p values from the target vector y\n",
    "    yy = y[p:]  # yy = (y_{t+p+1}, ..., y_n)\n",
    "\n",
    "    # Here we use fit_intercept=False since we do not want to include an intercept term in the AR model\n",
    "    regr = lm.LinearRegression(fit_intercept=False)\n",
    "    regr.fit(Phi,yy)    \n",
    "\n",
    "    return regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_nar(y, p, nhl):\n",
    "    \"\"\"Fits an AR(p) model. The loss function is the sum of squared errors from t=p+1 to t=n.\n",
    "\n",
    "    :param y: array (n,), training data points\n",
    "    :param p: int, AR model order\n",
    "    :return theta: array (p,), learnt AR coefficients\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of training data points\n",
    "    n = y.shape[0]\n",
    "    \n",
    "    # Construct the regression matrix\n",
    "    Phi = np.zeros((n-p, p))# <COMPLETE THIS LINE>\n",
    "    for j in range(p):\n",
    "        Phi[:,j] = y[(p-(j+1)): (n-(j+1)), 0] # <COMPLETE THIS LINE>\n",
    "    \n",
    "    # Drop the first p values from the target vector y\n",
    "    yy = y[p:].ravel()  # yy = (y_{t+p+1}, ..., y_n)\n",
    "\n",
    "    # Here we use fit_intercept=False since we do not want to include an intercept term in the AR model\n",
    "    regr =  MLPRegressor(hidden_layer_sizes = nhl, max_iter = 1000).fit(Phi, yy)    \n",
    "\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711d1a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ts(ts, plot_ma=True, plot_intervals=True, window=30,\n",
    "            figsize=(15,5), interval=5):\n",
    "    '''\n",
    "    Plot ts with rolling mean and 95% confidence interval with rolling std.\n",
    "    :parameter    \n",
    "      :param ts: pandas Series    \n",
    "      :param window: num - for rolling stats\n",
    "      :param plot_ma: bool - whether plot moving average\n",
    "      :param plot_intervals: bool - whether plot upper and lower bounds\n",
    "      :interval: frequency of X axis Ticks\n",
    "    '''\n",
    "    # Mean and STD Rolling\n",
    "    rolling_mean = ts.rolling(window=window).mean()    \n",
    "    rolling_std = ts.rolling(window=window).std()\n",
    "    \n",
    "    # Plot Space\n",
    "    plt.figure(figsize=figsize)    \n",
    "    plt.title(ts.name)    \n",
    "    plt.plot(ts[window:], label='Actual values', color=\"black\")   \n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=interval))\n",
    "\n",
    "    # Paint the series\n",
    "    if plot_ma:        \n",
    "        plt.plot(rolling_mean, 'g', label='MA'+str(window),\n",
    "               color=\"red\")    \n",
    "        \n",
    "    # Plot the bounds \n",
    "    if plot_intervals:\n",
    "        lower_bound = rolling_mean - (1.96 * rolling_std)\n",
    "        upper_bound = rolling_mean + (1.96 * rolling_std)\n",
    "    \n",
    "    # filler\n",
    "    \n",
    "    plt.fill_between(x=ts.index, y1=lower_bound, y2=upper_bound,\n",
    "                    color='lightskyblue', alpha=0.4)\n",
    "    \n",
    "    plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 90-degrees\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f809ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_outliers(ts, name_item=None, perc=0.01, figsize=(15,5), interval=3, plot=0):\n",
    "    \n",
    "    '''\n",
    "    Find outliers using sklearn unsupervised support vetcor machine.\n",
    "        :parameter\n",
    "        :param ts: pandas Series\n",
    "        :param perc: float - percentage of outliers to look for\n",
    "        :return\n",
    "            dtf with raw ts, outlier 1/0 (yes/no), numeric index\n",
    "    '''\n",
    "    # SVM Params #\n",
    "    #gamma# inverse of the radius of influence of samples selected by model as support vectors\n",
    "    #C# The larger the smaller the Margin accepted. The lower the larger the margin \n",
    "    \n",
    "    \n",
    "    ## fit svm Radial Basis Function\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    ts_scaled = scaler.fit_transform(ts.values.reshape(-1,1))\n",
    "    model = svm.OneClassSVM(nu=perc, kernel=\"rbf\", gamma=0.01)\n",
    "    model.fit(ts_scaled)\n",
    "    \n",
    "    ## dtf output\n",
    "    dtf_outliers = ts.to_frame(name=\"ts\")\n",
    "    dtf_outliers[\"index\"] = range(len(ts))\n",
    "    dtf_outliers[\"outlier\"] = model.predict(ts_scaled)\n",
    "    dtf_outliers[\"outlier\"] = dtf_outliers[\"outlier\"].apply(lambda\n",
    "                                              x: 1 if x==-1 else 0)\n",
    "    if plot:\n",
    "        ## plot\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        ax.set(title=\"Outliers detection: found \"\n",
    "               +str(sum(dtf_outliers[\"outlier\"]==1))) + ' of product = ' + name_item\n",
    "        ax.plot(dtf_outliers[\"ts\"],\n",
    "                color=\"black\")\n",
    "        ax.scatter(x=dtf_outliers[dtf_outliers[\"outlier\"]==1][\"index\"],\n",
    "                   y=dtf_outliers[dtf_outliers[\"outlier\"]==1]['ts'],\n",
    "                   color='red')\n",
    "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=interval))\n",
    "        plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 90-degrees\n",
    "\n",
    "        ax.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    return dtf_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers_plot(dtf_outliers, name_item= None, figsize=(15,5), interval=3, filter_threshold=None):\n",
    "        '''\n",
    "        Plots the DF object returned from the find_outliers function\n",
    "            :parameter\n",
    "            :param dtf_outliers: pandas Dataframe. Must have columns \"outlier\" (bool) and 'ts' (float), index must be \n",
    "                timestamp \n",
    "            :param perc: float - percentage of outliers to look for\n",
    "            :name_item: String for title purpose\n",
    "            :interval: frequency of X axis Ticks\n",
    "\n",
    "            :return\n",
    "                dtf with raw ts, outlier 1/0 (yes/no), numeric index\n",
    "        '''\n",
    "        # Copy the df not to modify inplace\n",
    "        dtf_outliers = dtf_outliers.copy()\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Paint the signal\n",
    "        ax.plot(dtf_outliers[\"ts\"],\n",
    "                color=\"black\")\n",
    "        \n",
    "        # Filter anomalies to get the viral anomalies only\n",
    "        if filter_threshold is not None:\n",
    "            thresh = dtf_outliers.ts.mean() + dtf_outliers.ts.std() * filter_threshold\n",
    "            \n",
    "            idx = dtf_outliers[dtf_outliers['ts'] < thresh ].index\n",
    "            dtf_outliers.loc[idx, 'outlier'] = 0\n",
    "\n",
    "        # Scatter points\n",
    "        ax.scatter(x=dtf_outliers[dtf_outliers[\"outlier\"]==1][\"index\"],\n",
    "                   y=dtf_outliers[dtf_outliers[\"outlier\"]==1]['ts'],\n",
    "                   color='red')\n",
    "        \n",
    "        # Title + Ticks\n",
    "        ax.set(title=\"Outliers detection: found \" +str(sum(dtf_outliers[\"outlier\"]==1))+ ' of product = ' + name_item) \n",
    "\n",
    "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=interval))\n",
    "        plt.xticks(rotation = 90) # Rotates X-Axis Ticks by 90-degrees\n",
    "\n",
    "        ax.grid(True)\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35300d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating user-defined function for arranging the results obtained from model into readable format\n",
    "\n",
    "def inspect(results):\n",
    "    '''\n",
    "    Rearranges the result object from the rules function in apriori algorithm (apyori)\n",
    "        :parameter\n",
    "        :results: rules object out of  apriori() function (apyori package)  \n",
    "\n",
    "        :return\n",
    "            zipped object ready for the pd.Dataframe transformation to be visualised\n",
    "    '''\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
    "    supports    = [result[1] for result in results]\n",
    "    confidences = [result[2][0][2] for result in results]\n",
    "    lifts       = [result[2][0][3] for result in results]\n",
    "    \n",
    "    return list(zip(lhs, rhs, supports, confidences, lifts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f01751dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def check_stationarity(series):\n",
    "    # Copied from https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "\n",
    "    result = adfuller(series.values)\n",
    "\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "\n",
    "    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n",
    "        print(\"\\u001b[32mStationary\\u001b[0m\")\n",
    "    else:\n",
    "        print(\"\\x1b[31mNon-stationary\\x1b[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
